\section{Methodology}\label{sec:methodology}
\task{Consider the title. The method might be better than the methodology}

This section will cover the methodology used in this project. In addition, it will cover the tools, datasets, and methods used to generate and keep a \gls{void} description updated.

\subsection{GraphDB}\label{sec:graphdb}
This section will cover the choice of the graph database used in this project. It will also cover the datasets used in this project.

There were many popular choices for databases.~\cite{best-graph-databases} mentions many popular graph databases and lists some of the pros and cons of each, such as Neo4j, Stardog, ArangoDB, and GraphDB. At first, Neo4j was considered, as it was often mentioned in the literature we read, but since it is not a triple store, it is not directly able to use the SPARQL query language~\cite{neo4j:-a-reasonable-RDF-graph-database}. Instead, we would have to learn to use Cypher, Neo4j's graph query language~\cite{cypher-query-language}, or translate a SPARQL query to Cypher.

Instead, we chose to use GraphDB, as it uses the SPARQL query language, was free for the purposes we needed, and it was easy to set up and use, making it a good choice for our project.

Upon choosing a database to work with, we used docker to set up a local instance of GraphDB. By doing this, we could easily manage and use our dataset for testing. We used the guide provided by GraphDB~\cite{docker-graphDB} and followed the steps to set up a local instance of GraphDB.

\subsubsection{Dataset}\label{sec:dataset}
It was debated whether to use a pre-existing dataset or create a simple one for testing. Finally, it was decided to create a simple dataset to test different methods of generating a \gls{void} description. This dataset was small, with around 150 Pokemon, their types, and evolutions. This dataset was created in a .ttl file and imported into GraphDB.
After everything worked as intended, we found a larger pre-existing dataset to show a more realistic example of how a \gls{void} description could be generated. This dataset was the "Waterloo SPRAQL Diversity Test Suit (WatDiv) v0.6", containing 10 million triples. The dataset's contents are not crucial for this project, but they should be a good example of generating a void description from a larger dataset.

\subsection{Void Generation}\label{sec:void}
This section will cover our implementation of void generation.

The first step to generating a \gls{void} description was to use a naive query; this would look at the entire dataset and generate a \gls{void} description based on the data. The naive query was a simple query that counted the number of subjects, predicates, objects, and triples. This was done to have a description that could be continuously updated. After this, every time the dataset is updated, a script would read the changes instead of running the naive query and update the \gls{void} description accordingly. By looking at the elements that have been added and whether or not they already exist in the current dataset. This was done to reduce the time it would take to update a \gls{void} description, by specifying the values to update, instead of looking through the entire dataset every time and creating a new \gls{void} description.

\subsubsection{Void Generation Methods}\label{sec:voidmethods}
This section will detail each part of the pipeline used to create a void description.
\task{Add only the most important parts of our implementation and the rest in the appendix.}

% \begin{listing}[htb!]
%     \begin{minted}{python}
%     \end{minted}
%     \caption{}
%     \label{}
% \end{listing}

% Frequency and size of updates to the dataset may be a constraint worth exploringâ€”frequent minor updates vs infrequent significant updates.

% If we analyze the script and deem certain parts overhead, which could be reduced if the algorithm was implemented directly in the database. If someone asks why we did not implement the algorithms in the database implementation, we need the arguments to back up our decisions. This is also true for other decisions.


%Void update will concern:
%size of the database
%triples in the query
%total running time
%cache size
%same, but with void generation

\subsection{Data concerns}\label{sec:concerns}
This section will cover the data that the experiments are concerned with in regards to updating the void description and also to generating the void description.


When looking at what experiments for the project, we need to consider what data we want to concern us with. To determine this, we need to look at what data is relevant to the project, and what we want to compare between update and generation.
One of these data points would be the size of the database. Since the size of the database could have an impact on how long it takes to update the void description, we need to consider this. This is