\section{Methodology}\label{sec:methodology}
\task{Consider title. Method might be better than Methodology}

This section will cover the methodology used in this project. It will cover the tools used, the datasets used, and the methods used to generate and keep a \gls{void} description updated.

\subsection{GraphDB}\label{sec:graphdb}
This section will cover the choice of the graph database used in this project. It will also cover the datasets used in this project.

There were many popular choices for databases.~\cite{best-graph-databases} mentions many popular graph databases and lists some of the pros and cons of each, such as Neo4j, Stardog, ArangoDB, and GraphDB. At first, Neo4j was considered, as it was often mentioned in the literature we read, but since it is not a triple store, it is not directly able to use the SPARQL query language~\cite{neo4j:-a-reasonable-RDF-graph-database}. Instead, we would have to learn to use Cypher, Neo4j's graph query language~\cite{cypher-query-language}, or translate a SPARQL query to Cypher.

Instead, we chose to use GraphDB, as it uses the SPARQL query language, was free for the purposes we needed, and it was easy to set up and use, making it a good choice for our project.

Upon choosing a database to work with, we used docker to set up a local instance of GraphDB. By doing this, we could easily manage and use our dataset for testing purposes. We used the guide provided by GraphDB~\cite{docker-graphDB} and followed the steps to set up a local instance of GraphDB.

\subsubsection{Dataset}\label{sec:dataset}
It was debated whether to use a pre-existing dataset, or to create a simple dataset to use for testing. It was decided to create a simple dataset first, to test different methods of generating a \gls{void} description. This dataset was a small dataset, with arround 150 Pokemon, their types, and evolutions. This dataset was created in a .ttl file, and imported into GraphDB.
After everything seemed to be working as intended, we found a larger pre-existing dataset, to show a more realistic example of how a \gls{void} description could be generated. This dataset was the "Waterloo SPRAQL Diversity Test Suit (WatDiv) v0.6", the dataset containing 10 million triples. The contents of the dataset is not important for this project, but should be a good example of generating a void description from a larger dataset.

\subsection{Void Generation}\label{sec:void}
This section will cover our implementation of void generation.

The first step to generating a \gls{void} description was to use a naive query, this would look at the entire dataset and generate a \gls{void} description based on the data. The naive query was a simple query that counted the number of subjects, predicates, objects, and triples. This was done to have a description that could then be continuosly keep updated. After this, everytime the dataset would be updated, instead of running the naive query, a script would read the changes and update the \gls{void} description accordingly. By looking at the elements added, and whether or not they already exist in the current dataset. This was done in an attempt to reduce the time it would take to update a \gls{void} description, by specifying the values to update, instead of looking through the entire dataset everytime, and just creating a new \gls{void} description.

\subsubsection{Void Generation Methods}\label{sec:voidmethods}
This section will go into details for each part of the pipeline used to create a void description.
\task{Add only the most important parts of our implementation, and add the rest in the appendix.}

% \begin{listing}[htb!]
%     \begin{minted}{python}
%     \end{minted}
%     \caption{}
%     \label{}
% \end{listing}

